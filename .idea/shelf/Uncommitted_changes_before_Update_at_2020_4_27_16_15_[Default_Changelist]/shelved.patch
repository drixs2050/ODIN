Index: Process.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>from datetime import datetime\r\nfrom create import *\r\nimport psycopg2\r\nimport sys\r\n\r\ndef archive(username, infolist):\r\n\tconn = psycopg2.connect(user=username, database='odin')\r\n\tcursor = conn.cursor()\r\n\tcursor.execute(\"SELECT EXISTS(SELECT * FROM information_schema.tables WHERE table_schema = 'public' AND table_name = 'archive');\")\r\n\tif cursor.fetchone()[0] == False:\r\n\t\tattr = {'payload': 'json', 'processed_by': 'varchar', 'processed_on': 'timestamp', 'archived_on': 'timestamp'}\r\n\t\tcreateTable('archive', attr, username)\r\n\tfor i in infolist:\r\n\t\tprocessed_time = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S.%f')\r\n\t\t\r\n\t\ti['archived_on'] = processed_time\r\n\t\ti['processed_by'] = username\r\n\t\tinsertTableJson(i, username)\r\n\t\tinsertPayload(username)\r\n\r\ndef processing(username):\r\n\tconn = psycopg2.connect(user=username, database='odin')\r\n\tcursor = conn.cursor()\r\n\tcursor.execute(\"SELECT payload from incoming;\")\r\n\tincoming_data = []\r\n\tfor row in cursor.fetchall():\r\n\t\tincoming_data.append(row[0])\r\n\tconn.close()\r\n\treturn incoming_data\r\n\r\n\r\ndef execute(username):\r\n\tincoming_data = processing(username)\r\n\t#For creating tables\r\n\tarchive_lst = []\r\n\tfor json in incoming_data:\r\n\t\tcurrent_tables = showAllTablesODIN(False, username)\r\n\t\tif json['name'].lower() == 'grouper' and not (json['name'].lower() in current_tables):\r\n\t\t\tvar_dict = {}\r\n\t\t\tmax_attribute_len = 0\r\n\t\t\tmax_index = 0\r\n\t\t\tfor i in range(len(incoming_data)):\r\n\t\t\t\tif (len(incoming_data[i]) > max_attribute_len):\r\n\t\t\t\t\tmax_attribute_len = len(incoming_data[i])\r\n\t\t\t\t\tmax_index = i\r\n\t\t\tfor column in incoming_data[max_index]:\r\n\t\t\t\tif type(incoming_data[max_index][column]) == type({}):\r\n\t\t\t\t\tvar_dict['stemname'] = 'varchar'\r\n\t\t\t\t\tvar_dict['numstems'] = 'Int'\r\n\t\t\t\telse:\r\n\t\t\t\t\tvar_dict[column] = 'varchar'\r\n\t\t\tcreateTable(json['name'], var_dict, username)\r\n\t\tif (json['name'].lower() in current_tables):\r\n\t\t\tprocessed_time = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S.%f')\r\n\t\t\t#print(showAllAttributes(username, json['name']))\r\n\t\t\tinsertTableJson(json,username)\r\n\t\t\tsingle_archive = {'name': 'archive', 'processed_on': processed_time}\r\n\t\t\tarchive_lst.append(single_archive)\r\n\tarchive(username, archive_lst)\r\n\t\t\t\r\n\t\t\t\r\nif __name__ == \"__main__\":\r\n\tprocessing(sys.argv[1])\r\n\texecute(sys.argv[1])\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
--- Process.py	(revision bb00b87e2c1b2f7e85a180772e41972d506091bb)
+++ Process.py	(date 1588018168940)
@@ -12,8 +12,7 @@
 		createTable('archive', attr, username)
 	for i in infolist:
 		processed_time = datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S.%f')
-		
-		i['archived_on'] = processed_time
+		i['archived_o-n'] = processed_time
 		i['processed_by'] = username
 		insertTableJson(i, username)
 		insertPayload(username)
